{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlCN72xZMbvM"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade google-cloud-language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SIQ9c4KJK5uw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/workspaces/analisis-del-discurso-del-odio-en-twitter-de-politicos-con-google-nlp/.env/ipaj-327601-ed35ac56f5a5.json' # En esta linea debe ir la ubicacion del archivo entre comillas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmoNdTv8VNgX"
      },
      "source": [
        "Analyze entity sentiment in a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ULib60tOUDx6"
      },
      "outputs": [],
      "source": [
        "from google.cloud import language_v1\n",
        "\n",
        "def sample_analyze_entity_sentiment(text_content):\n",
        "    \"\"\"\n",
        "    Analyzing Entity Sentiment in a String\n",
        "\n",
        "    Args:\n",
        "      text_content The text content to analyze\n",
        "    \"\"\"\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    # text_content = 'Grapes are good. Bananas are bad.'\n",
        "\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    # Optional. If not specified, the language is automatically detected.\n",
        "    # For list of supported languages:\n",
        "    # https://cloud.google.com/natural-language/docs/languages\n",
        "    language = \"es\"\n",
        "    document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
        "\n",
        "    # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    encoding_type = language_v1.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_entity_sentiment(request = {'document': document, 'encoding_type': encoding_type})\n",
        "    # Loop through entitites returned from the API\n",
        "    for entity in response.entities:\n",
        "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
        "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
        "        print(u\"Entity type: {}\".format(language_v1.Entity.Type(entity.type_).name))\n",
        "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
        "        print(u\"Salience score: {}\".format(entity.salience))\n",
        "        # Get the aggregate sentiment expressed for this entity in the provided document.\n",
        "        sentiment = entity.sentiment\n",
        "        print(u\"Entity sentiment score: {}\".format(sentiment.score))\n",
        "        print(u\"Entity sentiment magnitude: {}\".format(sentiment.magnitude))\n",
        "        # Loop over the metadata associated with entity. For many known entities,\n",
        "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
        "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
        "        # may have metadata for the address street_name, postal_code, et al.\n",
        "        for metadata_name, metadata_value in entity.metadata.items():\n",
        "            print(u\"{} = {}\".format(metadata_name, metadata_value))\n",
        "\n",
        "        # Loop over the mentions of this entity in the input document.\n",
        "        # The API currently supports proper noun mentions.\n",
        "        for mention in entity.mentions:\n",
        "            print(u\"Mention text: {}\".format(mention.text.content))\n",
        "            # Get the mention type, e.g. PROPER for proper noun\n",
        "            print(\n",
        "                u\"Mention type: {}\".format(language_v1.EntityMention.Type(mention.type_).name)\n",
        "            )\n",
        "\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    print(u\"Language of the text: {}\".format(response.language))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVtlk706TDqG",
        "outputId": "dd0d3f28-f5d8-4062-8519-272e0a42efc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Representative name for the entity: policias\n",
            "Entity type: PERSON\n",
            "Salience score: 0.3502153754234314\n",
            "Entity sentiment score: 0.10000000149011612\n",
            "Entity sentiment magnitude: 0.30000001192092896\n",
            "Mention text: policias\n",
            "Mention type: COMMON\n",
            "Representative name for the entity: integridad\n",
            "Entity type: OTHER\n",
            "Salience score: 0.1198473572731018\n",
            "Entity sentiment score: 0.10000000149011612\n",
            "Entity sentiment magnitude: 0.10000000149011612\n",
            "Mention text: integridad\n",
            "Mention type: COMMON\n",
            "Representative name for the entity: derecho\n",
            "Entity type: OTHER\n",
            "Salience score: 0.11862783879041672\n",
            "Entity sentiment score: 0.0\n",
            "Entity sentiment magnitude: 0.0\n",
            "Mention text: derecho\n",
            "Mention type: COMMON\n",
            "Representative name for the entity: soldados\n",
            "Entity type: PERSON\n",
            "Salience score: 0.10923637449741364\n",
            "Entity sentiment score: 0.0\n",
            "Entity sentiment magnitude: 0.0\n",
            "Mention text: soldados\n",
            "Mention type: COMMON\n",
            "Representative name for the entity: terrorismo\n",
            "Entity type: OTHER\n",
            "Salience score: 0.06522756069898605\n",
            "Entity sentiment score: 0.0\n",
            "Entity sentiment magnitude: 0.0\n",
            "Mention text: terrorismo\n",
            "Mention type: COMMON\n",
            "Representative name for the entity: armas\n",
            "Entity type: CONSUMER_GOOD\n",
            "Salience score: 0.06240098923444748\n",
            "Entity sentiment score: 0.10000000149011612\n",
            "Entity sentiment magnitude: 0.10000000149011612\n",
            "Mention text: armas\n",
            "Mention type: COMMON\n",
            "Representative name for the entity: personas\n",
            "Entity type: PERSON\n",
            "Salience score: 0.06171204522252083\n",
            "Entity sentiment score: 0.0\n",
            "Entity sentiment magnitude: 0.0\n",
            "Mention text: personas\n",
            "Mention type: COMMON\n",
            "Representative name for the entity: bienes\n",
            "Entity type: OTHER\n",
            "Salience score: 0.06171204522252083\n",
            "Entity sentiment score: 0.0\n",
            "Entity sentiment magnitude: 0.0\n",
            "Mention text: bienes\n",
            "Mention type: COMMON\n",
            "Representative name for the entity: accion\n",
            "Entity type: OTHER\n",
            "Salience score: 0.05102041736245155\n",
            "Entity sentiment score: -0.20000000298023224\n",
            "Entity sentiment magnitude: 0.20000000298023224\n",
            "Mention text: accion\n",
            "Mention type: COMMON\n",
            "Language of the text: es\n"
          ]
        }
      ],
      "source": [
        "text_content=\"Apoyemos el derecho de soldados y policias de utilizar sus armas para defender su integridad y para defender a las personas y bienes de la accion criminal del terrorismo vandalico\"\n",
        "sample_analyze_entity_sentiment(text_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEeFbhIUVQS9"
      },
      "source": [
        "Analyze sentiment app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7p-nKXEKVxw9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] movie_review_filename\n",
            "ipykernel_launcher.py: error: the following arguments are required: movie_review_filename\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "2",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Demonstrates how to make a simple call to the Natural Language API.\"\"\"\n",
        "\n",
        "import argparse\n",
        "\n",
        "from google.cloud import language_v1\n",
        "\n",
        "def print_result(annotations):\n",
        "    score = annotations.document_sentiment.score\n",
        "    magnitude = annotations.document_sentiment.magnitude\n",
        "\n",
        "    for index, sentence in enumerate(annotations.sentences):\n",
        "        sentence_sentiment = sentence.sentiment.score\n",
        "        print(\n",
        "            \"Sentence {} has a sentiment score of {}\".format(index, sentence_sentiment)\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        \"Overall Sentiment: score of {} with magnitude of {}\".format(score, magnitude)\n",
        "    )\n",
        "    return 0\n",
        "\n",
        "def analyze(movie_review_filename):\n",
        "    \"\"\"Run a sentiment analysis request on text within a passed filename.\"\"\"\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    with open(movie_review_filename, \"r\") as review_file:\n",
        "        # Instantiates a plain text document.\n",
        "        content = review_file.read()\n",
        "\n",
        "    document = language_v1.Document(content=content, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
        "    annotations = client.analyze_sentiment(request={'document': document})\n",
        "\n",
        "    # Print the results\n",
        "    print_result(annotations)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"movie_review_filename\",\n",
        "        help=\"The filename of the movie review you'd like to analyze.\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    analyze(args.movie_review_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_7_7lFAV6OI",
        "outputId": "b1417ba1-25bc-4b5f-a383-7fdda00b36b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence 0 has a sentiment score of 0.0\n",
            "Sentence 1 has a sentiment score of 0.20000000298023224\n",
            "Sentence 2 has a sentiment score of 0.30000001192092896\n",
            "Sentence 3 has a sentiment score of 0.8999999761581421\n",
            "Sentence 4 has a sentiment score of -0.20000000298023224\n",
            "Sentence 5 has a sentiment score of 0.10000000149011612\n",
            "Sentence 6 has a sentiment score of 0.30000001192092896\n",
            "Sentence 7 has a sentiment score of -0.10000000149011612\n",
            "Sentence 8 has a sentiment score of 0.0\n",
            "Sentence 9 has a sentiment score of 0.10000000149011612\n",
            "Sentence 10 has a sentiment score of 0.30000001192092896\n",
            "Sentence 11 has a sentiment score of 0.20000000298023224\n",
            "Sentence 12 has a sentiment score of 0.699999988079071\n",
            "Sentence 13 has a sentiment score of 0.0\n",
            "Sentence 14 has a sentiment score of 0.800000011920929\n",
            "Sentence 15 has a sentiment score of 0.10000000149011612\n",
            "Sentence 16 has a sentiment score of 0.6000000238418579\n",
            "Sentence 17 has a sentiment score of -0.10000000149011612\n",
            "Sentence 18 has a sentiment score of 0.10000000149011612\n",
            "Sentence 19 has a sentiment score of 0.699999988079071\n",
            "Sentence 20 has a sentiment score of 0.6000000238418579\n",
            "Sentence 21 has a sentiment score of 0.4000000059604645\n",
            "Sentence 22 has a sentiment score of 0.20000000298023224\n",
            "Sentence 23 has a sentiment score of 0.4000000059604645\n",
            "Sentence 24 has a sentiment score of 0.20000000298023224\n",
            "Sentence 25 has a sentiment score of 0.0\n",
            "Sentence 26 has a sentiment score of 0.10000000149011612\n",
            "Sentence 27 has a sentiment score of 0.8999999761581421\n",
            "Sentence 28 has a sentiment score of 0.8999999761581421\n",
            "Sentence 29 has a sentiment score of 0.6000000238418579\n",
            "Sentence 30 has a sentiment score of 0.30000001192092896\n",
            "Sentence 31 has a sentiment score of 0.699999988079071\n",
            "Sentence 32 has a sentiment score of 0.5\n",
            "Sentence 33 has a sentiment score of 0.30000001192092896\n",
            "Sentence 34 has a sentiment score of 0.800000011920929\n",
            "Sentence 35 has a sentiment score of 0.20000000298023224\n",
            "Sentence 36 has a sentiment score of 0.699999988079071\n",
            "Sentence 37 has a sentiment score of 0.800000011920929\n",
            "Sentence 38 has a sentiment score of 0.0\n",
            "Sentence 39 has a sentiment score of 0.10000000149011612\n",
            "Sentence 40 has a sentiment score of 0.4000000059604645\n",
            "Sentence 41 has a sentiment score of 0.30000001192092896\n",
            "Sentence 42 has a sentiment score of 0.20000000298023224\n",
            "Sentence 43 has a sentiment score of 0.4000000059604645\n",
            "Sentence 44 has a sentiment score of 0.20000000298023224\n",
            "Sentence 45 has a sentiment score of 0.5\n",
            "Sentence 46 has a sentiment score of 0.10000000149011612\n",
            "Sentence 47 has a sentiment score of 0.4000000059604645\n",
            "Sentence 48 has a sentiment score of 0.10000000149011612\n",
            "Sentence 49 has a sentiment score of 0.20000000298023224\n",
            "Sentence 50 has a sentiment score of 0.30000001192092896\n",
            "Sentence 51 has a sentiment score of 0.10000000149011612\n",
            "Sentence 52 has a sentiment score of 0.5\n",
            "Sentence 53 has a sentiment score of 0.5\n",
            "Sentence 54 has a sentiment score of -0.30000001192092896\n",
            "Sentence 55 has a sentiment score of 0.5\n",
            "Sentence 56 has a sentiment score of 0.4000000059604645\n",
            "Sentence 57 has a sentiment score of 0.20000000298023224\n",
            "Sentence 58 has a sentiment score of 0.10000000149011612\n",
            "Sentence 59 has a sentiment score of -0.30000001192092896\n",
            "Sentence 60 has a sentiment score of 0.20000000298023224\n",
            "Sentence 61 has a sentiment score of 0.20000000298023224\n",
            "Sentence 62 has a sentiment score of 0.30000001192092896\n",
            "Sentence 63 has a sentiment score of 0.4000000059604645\n",
            "Sentence 64 has a sentiment score of 0.10000000149011612\n",
            "Sentence 65 has a sentiment score of 0.20000000298023224\n",
            "Sentence 66 has a sentiment score of 0.20000000298023224\n",
            "Sentence 67 has a sentiment score of 0.4000000059604645\n",
            "Sentence 68 has a sentiment score of 0.8999999761581421\n",
            "Sentence 69 has a sentiment score of 0.0\n",
            "Sentence 70 has a sentiment score of 0.20000000298023224\n",
            "Sentence 71 has a sentiment score of 0.20000000298023224\n",
            "Sentence 72 has a sentiment score of 0.20000000298023224\n",
            "Sentence 73 has a sentiment score of 0.10000000149011612\n",
            "Sentence 74 has a sentiment score of 0.30000001192092896\n",
            "Sentence 75 has a sentiment score of 0.0\n",
            "Sentence 76 has a sentiment score of 0.5\n",
            "Sentence 77 has a sentiment score of 0.30000001192092896\n",
            "Sentence 78 has a sentiment score of 0.20000000298023224\n",
            "Sentence 79 has a sentiment score of 0.5\n",
            "Sentence 80 has a sentiment score of 0.5\n",
            "Sentence 81 has a sentiment score of 0.20000000298023224\n",
            "Sentence 82 has a sentiment score of 0.0\n",
            "Sentence 83 has a sentiment score of 0.10000000149011612\n",
            "Sentence 84 has a sentiment score of 0.5\n",
            "Sentence 85 has a sentiment score of 0.0\n",
            "Sentence 86 has a sentiment score of 0.5\n",
            "Sentence 87 has a sentiment score of 0.0\n",
            "Sentence 88 has a sentiment score of 0.4000000059604645\n",
            "Sentence 89 has a sentiment score of 0.10000000149011612\n",
            "Sentence 90 has a sentiment score of 0.6000000238418579\n",
            "Sentence 91 has a sentiment score of 0.4000000059604645\n",
            "Sentence 92 has a sentiment score of 0.699999988079071\n",
            "Sentence 93 has a sentiment score of 0.20000000298023224\n",
            "Sentence 94 has a sentiment score of -0.30000001192092896\n",
            "Sentence 95 has a sentiment score of 0.800000011920929\n",
            "Sentence 96 has a sentiment score of 0.30000001192092896\n",
            "Sentence 97 has a sentiment score of 0.8999999761581421\n",
            "Sentence 98 has a sentiment score of 0.30000001192092896\n",
            "Sentence 99 has a sentiment score of 0.30000001192092896\n",
            "Sentence 100 has a sentiment score of 0.0\n",
            "Sentence 101 has a sentiment score of 0.0\n",
            "Sentence 102 has a sentiment score of 0.4000000059604645\n",
            "Sentence 103 has a sentiment score of 0.5\n",
            "Sentence 104 has a sentiment score of 0.0\n",
            "Sentence 105 has a sentiment score of 0.20000000298023224\n",
            "Sentence 106 has a sentiment score of 0.10000000149011612\n",
            "Sentence 107 has a sentiment score of 0.30000001192092896\n",
            "Sentence 108 has a sentiment score of 0.30000001192092896\n",
            "Sentence 109 has a sentiment score of 0.8999999761581421\n",
            "Sentence 110 has a sentiment score of 0.4000000059604645\n",
            "Sentence 111 has a sentiment score of 0.6000000238418579\n",
            "Sentence 112 has a sentiment score of 0.20000000298023224\n",
            "Sentence 113 has a sentiment score of 0.20000000298023224\n",
            "Overall Sentiment: score of 0.30000001192092896 with magnitude of 43.0\n"
          ]
        }
      ],
      "source": [
        "analyze('/workspaces/analisis-del-discurso-del-odio-en-twitter-de-politicos-con-google-nlp/dataset/OIZuluaga.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-3zp0NdCQw"
      },
      "source": [
        "Analyze sentiment in a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7TVa2jhtdAu1"
      },
      "outputs": [],
      "source": [
        "from google.cloud import language_v1\n",
        "\n",
        "def sample_analyze_sentiment(text_content):\n",
        "    \"\"\"\n",
        "    Analyzing Sentiment in a String\n",
        "\n",
        "    Args:\n",
        "      text_content The text content to analyze\n",
        "    \"\"\"\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    # text_content = 'I am so happy and joyful.'\n",
        "\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    # Optional. If not specified, the language is automatically detected.\n",
        "    # For list of supported languages:\n",
        "    # https://cloud.google.com/natural-language/docs/languages\n",
        "    language = \"es\"\n",
        "    document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
        "\n",
        "    # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    encoding_type = language_v1.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_sentiment(request = {'document': document, 'encoding_type': encoding_type})\n",
        "    # Get overall sentiment of the input document\n",
        "    print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
        "    print(\n",
        "        u\"Document sentiment magnitude: {}\".format(\n",
        "            response.document_sentiment.magnitude\n",
        "        )\n",
        "    )\n",
        "    # Get sentiment for all sentences in the document\n",
        "    for sentence in response.sentences:\n",
        "        print(u\"Sentence text: {}\".format(sentence.text.content))\n",
        "        print(u\"Sentence sentiment score: {}\".format(sentence.sentiment.score))\n",
        "        print(u\"Sentence sentiment magnitude: {}\".format(sentence.sentiment.magnitude))\n",
        "\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    print(u\"Language of the text: {}\".format(response.language))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCJ_mc8pdJCP",
        "outputId": "b79878d9-a073-4390-b44d-16318b80a7fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document sentiment score: 0.10000000149011612\n",
            "Document sentiment magnitude: 0.10000000149011612\n",
            "Sentence text: Apoyemos el derecho de soldados y policias de utilizar sus armas para defender su integridad y para defender a las personas y bienes de la accion criminal del terrorismo vandalico\n",
            "Sentence sentiment score: 0.10000000149011612\n",
            "Sentence sentiment magnitude: 0.10000000149011612\n",
            "Language of the text: es\n"
          ]
        }
      ],
      "source": [
        "text_content='Apoyemos el derecho de soldados y policias de utilizar sus armas para defender su integridad y para defender a las personas y bienes de la accion criminal del terrorismo vandalico'\n",
        "sample_analyze_sentiment(text_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDB_Wp2cfij5"
      },
      "source": [
        "Detect sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81vmz0IDfjqg",
        "outputId": "91f206b6-9552-408f-8441-951606603eaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: Apoyemos el derecho de soldados y policias de utilizar sus armas para defender su integridad y para defender a las personas y bienes de la accion criminal del terrorismo vandalico\n",
            "Sentiment: 0.10000000149011612, 0.10000000149011612\n"
          ]
        }
      ],
      "source": [
        "# Imports the Google Cloud client library\n",
        "from google.cloud import language_v1\n",
        "\n",
        "# Instantiates a client\n",
        "client = language_v1.LanguageServiceClient()\n",
        "\n",
        "# The text to analyze\n",
        "text = u\"Apoyemos el derecho de soldados y policias de utilizar sus armas para defender su integridad y para defender a las personas y bienes de la accion criminal del terrorismo vandalico\"\n",
        "document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
        "\n",
        "# Detects the sentiment of the text\n",
        "sentiment = client.analyze_sentiment(request={'document': document}).document_sentiment\n",
        "\n",
        "print(\"Text: {}\".format(text))\n",
        "print(\"Sentiment: {}, {}\".format(sentiment.score, sentiment.magnitude))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ViIuCqQgf8t"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRdc2TuKgn_h"
      },
      "source": [
        "Analyze sentiment in a Cloud Storage file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8_AJpP3jghN8"
      },
      "outputs": [],
      "source": [
        "from google.cloud import language_v1\n",
        "\n",
        "def sample_analyze_sentiment(gcs_content_uri):\n",
        "    \"\"\"\n",
        "    Analyzing Sentiment in text file stored in Cloud Storage\n",
        "\n",
        "    Args:\n",
        "      gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
        "      e.g. gs://[Your Bucket]/[Path to File]\n",
        "    \"\"\"\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    # gcs_content_uri = 'gs://cloud-samples-data/language/sentiment-positive.txt'\n",
        "\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    # Optional. If not specified, the language is automatically detected.\n",
        "    # For list of supported languages:\n",
        "    # https://cloud.google.com/natural-language/docs/languages\n",
        "    language = \"es\"\n",
        "    document = {\"gcs_content_uri\": gcs_content_uri, \"type_\": type_, \"language\": language}\n",
        "\n",
        "    # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    encoding_type = language_v1.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_sentiment(request = {'document': document, 'encoding_type': encoding_type})\n",
        "    # Get overall sentiment of the input document\n",
        "    print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
        "    print(\n",
        "        u\"Document sentiment magnitude: {}\".format(\n",
        "            response.document_sentiment.magnitude\n",
        "        )\n",
        "    )\n",
        "    # Get sentiment for all sentences in the document\n",
        "    for sentence in response.sentences:\n",
        "        print(u\"Sentence text: {}\".format(sentence.text.content))\n",
        "        print(u\"Sentence sentiment score: {}\".format(sentence.sentiment.score))\n",
        "        print(u\"Sentence sentiment magnitude: {}\".format(sentence.sentiment.magnitude))\n",
        "\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    print(u\"Language of the text: {}\".format(response.language))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbC2OeFBguYh",
        "outputId": "2c024c26-b53b-4213-8703-4642fd334699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document sentiment score: 0.4000000059604645\n",
            "Document sentiment magnitude: 2.0\n",
            "Sentence text: @LiliVanegasR Muchas gracias.\n",
            "Sentence sentiment score: 0.800000011920929\n",
            "Sentence sentiment magnitude: 0.800000011920929\n",
            "Sentence text: Acabo de llegar del parque.\n",
            "Sentence sentiment score: 0.10000000149011612\n",
            "Sentence sentiment magnitude: 0.10000000149011612\n",
            "Sentence text: Un abrazo.,\n",
            "@adtamayo Abrazo Alexander.,\n",
            "@MaisAngel Gracias María Isabel.\n",
            "Sentence sentiment score: 0.0\n",
            "Sentence sentiment magnitude: 0.0\n",
            "Sentence text: Un abrazo.,\n",
            "@ElJuliSastoque @Educacionbogota Gracias Julian.\n",
            "Sentence sentiment score: 0.0\n",
            "Sentence sentiment magnitude: 0.0\n",
            "Sentence text: Abrazo y feliz noche.,\n",
            "Sentence sentiment score: 0.8999999761581421\n",
            "Sentence sentiment magnitude: 0.8999999761581421\n",
            "Language of the text: es\n"
          ]
        }
      ],
      "source": [
        "sample_analyze_sentiment('gs://testojpublikaj/testo.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import language_v1\n",
        "\n",
        "\n",
        "def sample_analyze_sentiment(gcs_content_uri):\n",
        "    \"\"\"\n",
        "    Analyzing Sentiment in text file stored in Cloud Storage\n",
        "\n",
        "    Args:\n",
        "      gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
        "      e.g. gs://[Your Bucket]/[Path to File]\n",
        "    \"\"\"\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    # gcs_content_uri = 'gs://cloud-samples-data/language/sentiment-positive.txt'\n",
        "\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    # Optional. If not specified, the language is automatically detected.\n",
        "    # For list of supported languages:\n",
        "    # https://cloud.google.com/natural-language/docs/languages\n",
        "    language = \"es\"\n",
        "    document = {\n",
        "        \"gcs_content_uri\": gcs_content_uri,\n",
        "        \"type_\": type_,\n",
        "        \"language\": language\n",
        "    }\n",
        "\n",
        "    # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    encoding_type = language_v1.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_sentiment(request={\n",
        "        'document': document,\n",
        "        'encoding_type': encoding_type\n",
        "    })\n",
        "    # Get overall sentiment of the input document\n",
        "    print(u\"Document sentiment score: {}\".format(\n",
        "        response.document_sentiment.score))\n",
        "    print(u\"Document sentiment magnitude: {}\".format(\n",
        "        response.document_sentiment.magnitude))\n",
        "    # Get sentiment for all sentences in the document\n",
        "    for sentence in response.sentences:\n",
        "        print((sentence.text.content), \",\", (sentence.sentiment.score), \",\",\n",
        "              (sentence.sentiment.magnitude))\n",
        "\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    print(u\"Language of the text: {}\".format(response.language))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document sentiment score: 0.4000000059604645\n",
            "Document sentiment magnitude: 2.0\n",
            "Sentence text: @LiliVanegasR Muchas gracias.\n",
            "Sentence sentiment score: 0.800000011920929\n",
            "Sentence sentiment magnitude: 0.800000011920929\n",
            "Sentence text: Acabo de llegar del parque.\n",
            "Sentence sentiment score: 0.10000000149011612\n",
            "Sentence sentiment magnitude: 0.10000000149011612\n",
            "Sentence text: Un abrazo.,\n",
            "@adtamayo Abrazo Alexander.,\n",
            "@MaisAngel Gracias María Isabel.\n",
            "Sentence sentiment score: 0.0\n",
            "Sentence sentiment magnitude: 0.0\n",
            "Sentence text: Un abrazo.,\n",
            "@ElJuliSastoque @Educacionbogota Gracias Julian.\n",
            "Sentence sentiment score: 0.0\n",
            "Sentence sentiment magnitude: 0.0\n",
            "Sentence text: Abrazo y feliz noche.,\n",
            "Sentence sentiment score: 0.8999999761581421\n",
            "Sentence sentiment magnitude: 0.8999999761581421\n",
            "Language of the text: es\n"
          ]
        }
      ],
      "source": [
        "archivo = (\"gs://testojpublikaj/testo.csv\")\n",
        "sample_analyze_sentiment(archivo)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "muestras de código de la API de Natural Language.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
