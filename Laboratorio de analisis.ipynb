{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlCN72xZMbvM"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade google-cloud-language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SIQ9c4KJK5uw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\n",
        "    'GOOGLE_APPLICATION_CREDENTIALS'] = '/workspaces/analisis-del-discurso-del-odio-en-twitter-de-politicos-con-google-nlp/.env/ipaj-327601-ed35ac56f5a5.json'  # En esta linea debe ir la ubicacion del archivo entre comillas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmoNdTv8VNgX"
      },
      "source": [
        "Analyze entity sentiment in a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULib60tOUDx6"
      },
      "outputs": [],
      "source": [
        "from google.cloud import language_v1\n",
        "\n",
        "\n",
        "def sample_analyze_entity_sentiment(text_content):\n",
        "    \"\"\"\n",
        "    Analyzing Entity Sentiment in a String\n",
        "\n",
        "    Args:\n",
        "      text_content The text content to analyze\n",
        "    \"\"\"\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    # text_content = 'Grapes are good. Bananas are bad.'\n",
        "\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    # Optional. If not specified, the language is automatically detected.\n",
        "    # For list of supported languages:\n",
        "    # https://cloud.google.com/natural-language/docs/languages\n",
        "    language = \"es\"\n",
        "    document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
        "\n",
        "    # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    encoding_type = language_v1.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_entity_sentiment(request={\n",
        "        'document': document,\n",
        "        'encoding_type': encoding_type\n",
        "    })\n",
        "    # Loop through entitites returned from the API\n",
        "    for entity in response.entities:\n",
        "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
        "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
        "        print(u\"Entity type: {}\".format(\n",
        "            language_v1.Entity.Type(entity.type_).name))\n",
        "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
        "        print(u\"Salience score: {}\".format(entity.salience))\n",
        "        # Get the aggregate sentiment expressed for this entity in the provided document.\n",
        "        sentiment = entity.sentiment\n",
        "        print(u\"Entity sentiment score: {}\".format(sentiment.score))\n",
        "        print(u\"Entity sentiment magnitude: {}\".format(sentiment.magnitude))\n",
        "        # Loop over the metadata associated with entity. For many known entities,\n",
        "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
        "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
        "        # may have metadata for the address street_name, postal_code, et al.\n",
        "        for metadata_name, metadata_value in entity.metadata.items():\n",
        "            print(u\"{} = {}\".format(metadata_name, metadata_value))\n",
        "\n",
        "        # Loop over the mentions of this entity in the input document.\n",
        "        # The API currently supports proper noun mentions.\n",
        "        for mention in entity.mentions:\n",
        "            print(u\"Mention text: {}\".format(mention.text.content))\n",
        "            # Get the mention type, e.g. PROPER for proper noun\n",
        "            print(u\"Mention type: {}\".format(\n",
        "                language_v1.EntityMention.Type(mention.type_).name))\n",
        "\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    print(u\"Language of the text: {}\".format(response.language))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVtlk706TDqG",
        "outputId": "dd0d3f28-f5d8-4062-8519-272e0a42efc0"
      },
      "outputs": [],
      "source": [
        "text_content = \"Apoyemos el derecho de soldados y policias de utilizar sus armas para defender su integridad y para defender a las personas y bienes de la accion criminal del terrorismo vandalico\"\n",
        "sample_analyze_entity_sentiment(text_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEeFbhIUVQS9"
      },
      "source": [
        "Analyze sentiment app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p-nKXEKVxw9"
      },
      "outputs": [],
      "source": [
        "\"\"\"Demonstrates how to make a simple call to the Natural Language API.\"\"\"\n",
        "\n",
        "import argparse\n",
        "\n",
        "from google.cloud import language_v1\n",
        "\n",
        "\n",
        "def print_result(annotations):\n",
        "    score = annotations.document_sentiment.score\n",
        "    magnitude = annotations.document_sentiment.magnitude\n",
        "\n",
        "    for index, sentence in enumerate(annotations.sentences):\n",
        "        sentence_sentiment = sentence.sentiment.score\n",
        "        print(\"Sentence {} has a sentiment score of {}\".format(\n",
        "            index, sentence_sentiment))\n",
        "\n",
        "    print(\"Overall Sentiment: score of {} with magnitude of {}\".format(\n",
        "        score, magnitude))\n",
        "    return 0\n",
        "\n",
        "\n",
        "def analyze(movie_review_filename):\n",
        "    \"\"\"Run a sentiment analysis request on text within a passed filename.\"\"\"\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    with open(movie_review_filename, \"r\") as review_file:\n",
        "        # Instantiates a plain text document.\n",
        "        content = review_file.read()\n",
        "\n",
        "    document = language_v1.Document(content=content,\n",
        "                                    type_=language_v1.Document.Type.PLAIN_TEXT)\n",
        "    annotations = client.analyze_sentiment(request={'document': document})\n",
        "\n",
        "    # Print the results\n",
        "    print_result(annotations)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=__doc__,\n",
        "        formatter_class=argparse.RawDescriptionHelpFormatter)\n",
        "    parser.add_argument(\n",
        "        \"movie_review_filename\",\n",
        "        help=\"The filename of the movie review you'd like to analyze.\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    analyze(args.movie_review_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_7_7lFAV6OI",
        "outputId": "b1417ba1-25bc-4b5f-a383-7fdda00b36b5"
      },
      "outputs": [],
      "source": [
        "analyze(\n",
        "    '/workspaces/analisis-del-discurso-del-odio-en-twitter-de-politicos-con-google-nlp/dataset/OIZuluaga.csv'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-3zp0NdCQw"
      },
      "source": [
        "Analyze sentiment in a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TVa2jhtdAu1"
      },
      "outputs": [],
      "source": [
        "from google.cloud import language_v1\n",
        "\n",
        "\n",
        "def sample_analyze_sentiment(text_content):\n",
        "    \"\"\"\n",
        "    Analyzing Sentiment in a String\n",
        "\n",
        "    Args:\n",
        "      text_content The text content to analyze\n",
        "    \"\"\"\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    # text_content = 'I am so happy and joyful.'\n",
        "\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    # Optional. If not specified, the language is automatically detected.\n",
        "    # For list of supported languages:\n",
        "    # https://cloud.google.com/natural-language/docs/languages\n",
        "    language = \"es\"\n",
        "    document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
        "\n",
        "    # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    encoding_type = language_v1.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_sentiment(request={\n",
        "        'document': document,\n",
        "        'encoding_type': encoding_type\n",
        "    })\n",
        "    # Get overall sentiment of the input document\n",
        "    print(u\"Document sentiment score: {}\".format(\n",
        "        response.document_sentiment.score))\n",
        "    print(u\"Document sentiment magnitude: {}\".format(\n",
        "        response.document_sentiment.magnitude))\n",
        "    # Get sentiment for all sentences in the document\n",
        "    for sentence in response.sentences:\n",
        "        print(u\"Sentence text: {}\".format(sentence.text.content))\n",
        "        print(u\"Sentence sentiment score: {}\".format(sentence.sentiment.score))\n",
        "        print(u\"Sentence sentiment magnitude: {}\".format(\n",
        "            sentence.sentiment.magnitude))\n",
        "\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    print(u\"Language of the text: {}\".format(response.language))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCJ_mc8pdJCP",
        "outputId": "b79878d9-a073-4390-b44d-16318b80a7fb"
      },
      "outputs": [],
      "source": [
        "text_content = 'Apoyemos el derecho de soldados y policias de utilizar sus armas para defender su integridad y para defender a las personas y bienes de la accion criminal del terrorismo vandalico'\n",
        "sample_analyze_sentiment(text_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDB_Wp2cfij5"
      },
      "source": [
        "Detect sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81vmz0IDfjqg",
        "outputId": "91f206b6-9552-408f-8441-951606603eaa"
      },
      "outputs": [],
      "source": [
        "# Imports the Google Cloud client library\n",
        "from google.cloud import language_v1\n",
        "\n",
        "# Instantiates a client\n",
        "client = language_v1.LanguageServiceClient()\n",
        "\n",
        "# The text to analyze\n",
        "text = u\"Apoyemos el derecho de soldados y policias de utilizar sus armas para defender su integridad y para defender a las personas y bienes de la accion criminal del terrorismo vandalico\"\n",
        "document = language_v1.Document(content=text,\n",
        "                                type_=language_v1.Document.Type.PLAIN_TEXT)\n",
        "\n",
        "# Detects the sentiment of the text\n",
        "sentiment = client.analyze_sentiment(request={\n",
        "    'document': document\n",
        "}).document_sentiment\n",
        "\n",
        "print(\"Text: {}\".format(text))\n",
        "print(\"Sentiment: {}, {}\".format(sentiment.score, sentiment.magnitude))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ViIuCqQgf8t"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRdc2TuKgn_h"
      },
      "source": [
        "Analyze sentiment in a Cloud Storage file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_AJpP3jghN8"
      },
      "outputs": [],
      "source": [
        "from google.cloud import language_v1\n",
        "\n",
        "\n",
        "def sample_analyze_sentiment(gcs_content_uri):\n",
        "    \"\"\"\n",
        "    Analyzing Sentiment in text file stored in Cloud Storage\n",
        "\n",
        "    Args:\n",
        "      gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
        "      e.g. gs://[Your Bucket]/[Path to File]\n",
        "    \"\"\"\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    # gcs_content_uri = 'gs://cloud-samples-data/language/sentiment-positive.txt'\n",
        "\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    # Optional. If not specified, the language is automatically detected.\n",
        "    # For list of supported languages:\n",
        "    # https://cloud.google.com/natural-language/docs/languages\n",
        "    language = \"es\"\n",
        "    document = {\n",
        "        \"gcs_content_uri\": gcs_content_uri,\n",
        "        \"type_\": type_,\n",
        "        \"language\": language\n",
        "    }\n",
        "\n",
        "    # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    encoding_type = language_v1.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_sentiment(request={\n",
        "        'document': document,\n",
        "        'encoding_type': encoding_type\n",
        "    })\n",
        "    # Get overall sentiment of the input document\n",
        "    print(u\"Document sentiment score: {}\".format(\n",
        "        response.document_sentiment.score))\n",
        "    print(u\"Document sentiment magnitude: {}\".format(\n",
        "        response.document_sentiment.magnitude))\n",
        "    # Get sentiment for all sentences in the document\n",
        "    for sentence in response.sentences:\n",
        "        print((sentence.text.content), \"+\", (sentence.sentiment.score), \"+\",\n",
        "              (sentence.sentiment.magnitude))\n",
        "\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    print(u\"Language of the text: {}\".format(response.language))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbC2OeFBguYh",
        "outputId": "2c024c26-b53b-4213-8703-4642fd334699"
      },
      "outputs": [],
      "source": [
        "sample_analyze_sentiment('gs://testojpublikaj/OIZuluaga.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import language_v1\n",
        "\n",
        "\n",
        "def sample_analyze_sentiment(gcs_content_uri):\n",
        "    \"\"\"\n",
        "    Analyzing Sentiment in text file stored in Cloud Storage\n",
        "\n",
        "    Args:\n",
        "      gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
        "      e.g. gs://[Your Bucket]/[Path to File]\n",
        "    \"\"\"\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    # gcs_content_uri = 'gs://cloud-samples-data/language/sentiment-positive.txt'\n",
        "\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    # Optional. If not specified, the language is automatically detected.\n",
        "    # For list of supported languages:\n",
        "    # https://cloud.google.com/natural-language/docs/languages\n",
        "    language = \"es\"\n",
        "    document = {\n",
        "        \"gcs_content_uri\": gcs_content_uri,\n",
        "        \"type_\": type_,\n",
        "        \"language\": language\n",
        "    }\n",
        "\n",
        "    # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    encoding_type = language_v1.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_sentiment(request={\n",
        "        'document': document,\n",
        "        'encoding_type': encoding_type\n",
        "    })\n",
        "    # Get overall sentiment of the input document\n",
        "    print(u\"Document sentiment score: {}\".format(\n",
        "        response.document_sentiment.score))\n",
        "    print(u\"Document sentiment magnitude: {}\".format(\n",
        "        response.document_sentiment.magnitude))\n",
        "    # Get sentiment for all sentences in the document\n",
        "    for sentence in response.sentences:\n",
        "        print((sentence.text.content), \",\", (sentence.sentiment.score), \",\",\n",
        "              (sentence.sentiment.magnitude))\n",
        "\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    print(u\"Language of the text: {}\".format(response.language))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "archivo = (\"gs://testojpublikaj/testo.csv\")\n",
        "sample_analyze_sentiment(archivo)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "muestras de código de la API de Natural Language.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
